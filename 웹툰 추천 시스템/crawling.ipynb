{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtoon = pd.read_csv(\"/Users/kh/Documents/ML_project/웹툰 추천 시스템/data/webtoon.csv\")\n",
    "title_list = list(webtoon[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://comic.naver.com/webtoon?tab=mon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CSS_SELECTOR, \"#content > div:nth-child(1) > ul > li:nth-child(1) > div > a > span > span\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왕과의 야행 보리 9.98\n",
      "신화급 귀속 아이템을 손에 넣었다 정선율 / 헤스 9.91\n",
      "귀촌리 황양 / 이대한 9.93\n",
      "별난식당 HO9 9.96\n",
      "환생천마 JP / 부겸 / 장영훈 9.90\n",
      "우아한 욕망 김종건 9.91\n",
      "회귀한 공작가의 막내도련님은 암살자 스윙뱃 / 커피라임 9.92\n",
      "수상한 다이어트 클럽 스프링 9.86\n",
      "어린이집 다니는 구나 구나 9.97\n",
      "진주 박만사, 백두 / 백승훈, 백두 9.91\n",
      "마왕을 그만둔 이유 김대일 / 이상혁 9.68\n",
      "토마토가 돼라! 뮤리 9.97\n",
      "여고생이 신인데 나만 괴롭힘 박장고 / 이우 9.68\n",
      "개같이 탈출 갬쟈 9.94\n",
      "녹빛자정의 연인 백작 9.96\n",
      "악당 가족이 독립을 반대한다 밋츄 / 하티 / 이흰 9.97\n",
      "제왕 김남규 / 애풍, 콘티메이커 9.92\n",
      "영업 천재가 되었다 혜림 / 댄킴 9.91\n",
      "좀비묵시록 82-08 달아 / 콘티메이커, 경우 / 박스오피스 9.75\n",
      "미친 재능의 플레이어 S-Nanyc / 호라칸 / 체나 9.75\n",
      "막장 악녀 LICO 9.86\n",
      "찔레꽃 그늘 아래 해람 / 홍이 9.92\n",
      "함부로 친절하지 말라 도림 / 류화 / 유세라 9.95\n",
      "보스리턴 양세준 9.85\n",
      "사랑, 그거 어떻게 하는 건데 이범 9.96\n",
      "시한부의 아이까지 뺏으려 합니다 랍스타 / 이루이 9.84\n",
      "달이 뜨지 않는 도시 뚱귤 9.82\n",
      "공녀님의 꽃밭에는 그들이 산다 검오리 / 영락 / 고겨울 9.85\n",
      "악녀교실 즛호 9.92\n",
      "엘프 홍작가 9.96\n",
      "제국 제일의 상속녀가 되었습니다 한강 / 요정용 9.91\n",
      "내가 왜 킬러?! 규잉 9.94\n",
      "학식의 꿈 으앵 9.95\n",
      "반려짐승 래형 9.95\n",
      "두 번째 삶은 힐링라이프? 당토 9.90\n",
      "찌질하지만 로맨스는 하고 싶어 상수 9.24\n",
      "고백어택 늠개 9.83\n",
      "다육이는 잘 자란다 도국 9.88\n",
      "어쌔신 크리드 - 잊혀진 사원 ARC, Ubisoft, NOHT / Tabii 9.88\n",
      "프로페서 다드래기 / 노리 / 김연우 9.44\n",
      "날 먹는 건 금지양! 조9 9.97\n",
      "컨트롤X 사이렌 / 서클 9.50\n",
      "나의 보이소프렌드 망공이 9.93\n",
      "포스트 팬데믹 좡좡 / 영명 / 한산이가 9.88\n",
      "선빵필승! 해미 9.03\n",
      "오늘의 일기예보 지휘 9.86\n",
      "처음을 줄게! 을승 9.81\n",
      "티엔다비스 - 완벽한 구원을 위하여 삼공 / 느링 / 김영지 9.93\n",
      "러브 똘츄얼리 김진경 7.77\n",
      "악취해결사 샘샘 9.94\n",
      "어느날 짝남에게 공작님이 빙의했다 다담 / 죽순 9.80\n"
     ]
    }
   ],
   "source": [
    "html = driver.page_source # 가져온 페이지의 source를 저장\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "items = soup.select(\"#content > div:nth-child(1) > ul > li\")\n",
    "base_url = \"https://comic.naver.com/\"\n",
    "for item in items:\n",
    "    # 제목 추출\n",
    "    title = item.select_one(\"div > a > span > span\").text.strip()\n",
    "    if title not in title_list:\n",
    "        # 저자 정보가 있는 여러 위치를 체크하여 첫 번째로 발견된 요소를 사용\n",
    "        author_element = item.select_one(\"div > div.ContentAuthor__author_wrap--fV7Lo > a, div > a.ContentAuthor__author--CTAAP\")\n",
    "        author = author_element.text.strip() if author_element else \"Author Not Found\"\n",
    "        \n",
    "        # 평점 추출\n",
    "        rating = item.select_one(\"div > div.rating_area > span > span\").text.strip()\n",
    "        print(title, author, rating)\n",
    "        \n",
    "    # detail_link = base_link + item.select_one(\"a.ContentTitle__title_area--x24vt\")['href']\n",
    "    # driver.get(base_url)\n",
    "    # new_page_html = driver.page_source\n",
    "    # detail_soup = BeautifulSoup(new_page_html, 'html.parser')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.soup = None\n",
    "        self.data = []\n",
    "\n",
    "    def fetchPage(self):\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(3)\n",
    "        self.soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        \n",
    "    def parseTAR(self): # T: title, A: author, R: rating\n",
    "        if self.soup is not None:\n",
    "            items = self.soup.select(\"#content > div:nth-child(1) > ul > li\")\n",
    "            for item in items:\n",
    "                # 제목 추출\n",
    "                title = item.select_one(\"div > a > span > span\").text.strip()\n",
    "                \n",
    "                # 저자 정보가 있는 여러 위치를 체크하여 첫 번째로 발견된 요소를 사용\n",
    "                author_element = item.select_one(\"div > div.ContentAuthor__author_wrap--fV7Lo > a, div > a.ContentAuthor__author--CTAAP\")\n",
    "                author = author_element.text.strip() if author_element else \"Author Not Found\"\n",
    "                \n",
    "                # 평점 추출\n",
    "                rating = item.select_one(\"div > div.rating_area > span > span\")\n",
    "\n",
    "                self.data.append({\n",
    "                'title': title,\n",
    "                'author': author,\n",
    "                'rating': rating})\n",
    "        else:\n",
    "            print(\"Soup is None. Call fetch_page() first\")\n",
    "\n",
    "    def parseGD(self): # G: genre, D: description\n",
    "        if self.soup is not None:\n",
    "            items \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content > div:nth-child(1) > ul > li:nth-child(1) > div > a > span > span\n",
    "#content > div:nth-child(1) > ul > li:nth-child(2) > div > a > span > span\n",
    "\n",
    "#content > div:nth-child(1) > ul > li:nth-child(1) > div > div.ContentAuthor__author_wrap--fV7Lo > a\n",
    "#content > div:nth-child(1) > ul > li:nth-child(2) > div > div.ContentAuthor__author_wrap--fV7Lo > a\n",
    "\n",
    "#content > div:nth-child(1) > ul > li:nth-child(1) > div > div.rating_area > span > span\n",
    "#content > div:nth-child(1) > ul > li:nth-child(2) > div > div.rating_area > span > span\n",
    "\n",
    "#content > div:nth-child(1) > ul > li:nth-child(3) > div > a.ContentAuthor__author--CTAAP\n",
    "\n",
    "#content > div:nth-child(1) > ul > li:nth-child(1) > div > a > span"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
